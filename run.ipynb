{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 허깅페이스 SentenceTransformer 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/food_detection/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch import Tensor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('clip-ViT-B-32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 크롤링한 메뉴 이미지 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['트레이 짜장',\n",
       " '차알 순두부',\n",
       " '깐풍가지새우',\n",
       " '로제샹궈',\n",
       " '제네럴 쏘 치킨',\n",
       " '마라샹궈',\n",
       " '유린기 샐러드',\n",
       " '차알 볶음밥',\n",
       " '마라 짬뽕',\n",
       " '차우멘',\n",
       " '공심채 볶음',\n",
       " '마파두부',\n",
       " '차알 순두부 핫팟',\n",
       " '오렌지 치킨',\n",
       " '몽골리안 비프',\n",
       " '차알 탕수육']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu_data_path = './datasets/차알/menu_차알'\n",
    "label_list = os.listdir(menu_data_path)\n",
    "for i, _ in enumerate(label_list):\n",
    "    if _ == 'menu_images.csv':\n",
    "        label_list.remove(_)\n",
    "        continue\n",
    "    label_list[i] = _.replace('.jpg','')\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "menu_original_images = []\n",
    "\n",
    "# 불러오는 이미지를 미리 보고 싶으시면 참조된 코드들을 해제하여\n",
    "# 한번에 최대 18개까지 미리 볼 수 있다\n",
    "\n",
    "# plt.figure(figsize=(16, 5))\n",
    "\n",
    "for i, filename in enumerate([filename for filename in os.listdir(menu_data_path) if filename.endswith(\".png\") or filename.endswith(\".jpg\")]):\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    image = Image.open(os.path.join(menu_data_path, filename)).convert(\"RGB\")\n",
    "\n",
    "    # plt.subplot(3, 6, i + 1)\n",
    "    # plt.imshow(image)\n",
    "    # plt.xticks([])\n",
    "    # plt.yticks([])\n",
    "\n",
    "    menu_original_images.append(image)\n",
    "\n",
    "# CLIP으로 feature extraction\n",
    "menu_encoded_images = model.encode(menu_original_images, batch_size=128, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 크롤링한 리뷰 이미지 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# 예시로 유린기 샐러드만 모아놓은 폴더를 지정했지만\n",
    "# 자유롭게 경로 변경하여 생성 가능\n",
    "test_data_path = './datasets/차알/crops/유린기 샐러드'\n",
    "\n",
    "test_original_images = []\n",
    "\n",
    "## 참조를 해제하면 불러오는 이미지들을 18개까지 미리 볼 수 있다\n",
    "\n",
    "# plt.figure(figsize=(16, 5))\n",
    "# start = 0\n",
    "# end = 17\n",
    "for i, filename in enumerate([filename for filename in os.listdir(test_data_path) if filename.endswith(\".png\") or filename.endswith(\".jpg\")]):\n",
    "    # if i < start:    \n",
    "    #   continue\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    image = Image.open(os.path.join(test_data_path, filename)).convert(\"RGB\")\n",
    "\n",
    "    # plt.subplot(3, 6, i-start + 1) \n",
    "    # plt.imshow(image)\n",
    "    # plt.xticks([])\n",
    "    # plt.yticks([])\n",
    "\n",
    "    test_original_images.append(image)\n",
    "\n",
    "    # if i == end:\n",
    "    #   break\n",
    "\n",
    "# CLIP으로 feature extraction\n",
    "test_encoded_images = model.encode(test_original_images, batch_size=128, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cosine 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a: Tensor, b: Tensor):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
    "    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n",
    "    \"\"\"\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(a)\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(b)\n",
    "\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n",
    "    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [0],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [0],\n",
       " [6],\n",
       " [6]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import queue\n",
    "\n",
    "query_chunk_size = 5000\n",
    "corpus_chunk_size = 100000\n",
    "max_pairs = 500000\n",
    "top_k = 1\n",
    "\n",
    "pairs = queue.PriorityQueue()\n",
    "min_score = -1\n",
    "num_added = 0\n",
    "\n",
    "score_function = cos_sim\n",
    "\n",
    "for corpus_start_idx in range(0, len(menu_encoded_images), corpus_chunk_size):\n",
    "    for query_start_idx in range(0, len(test_encoded_images), query_chunk_size):\n",
    "        scores = score_function(test_encoded_images[query_start_idx:query_start_idx+query_chunk_size], menu_encoded_images[corpus_start_idx:corpus_start_idx+corpus_chunk_size])\n",
    "        \n",
    "        scores_top_k_values, scores_top_k_idx = torch.topk(scores, min(top_k, len(scores[0])), dim=1, largest=True, sorted=False)\n",
    "        scores_top_k_values = scores_top_k_values.cpu().tolist()\n",
    "        scores_top_k_idx = scores_top_k_idx.cpu().tolist()\n",
    "\n",
    "        for query_itr in range(len(scores)):\n",
    "            for top_k_idx, corpus_itr in enumerate(scores_top_k_idx[query_itr]):\n",
    "                i = query_start_idx + query_itr\n",
    "                j = corpus_start_idx + corpus_itr\n",
    "\n",
    "                if i != j and scores_top_k_values[query_itr][top_k_idx] > min_score:\n",
    "                    pairs.put((scores_top_k_values[query_itr][top_k_idx], i, j))\n",
    "                    num_added += 1\n",
    "\n",
    "                    if num_added >= max_pairs:\n",
    "                        entry = pairs.get()\n",
    "                        min_score = entry[0]\n",
    "\n",
    "added_pairs = set() \n",
    "pairs_list = []\n",
    "while not pairs.empty():\n",
    "    score, i, j = pairs.get()\n",
    "    sorted_i, sorted_j = sorted([i, j])\n",
    "\n",
    "    if sorted_i != sorted_j and (sorted_i, sorted_j) not in added_pairs:\n",
    "        added_pairs.add((sorted_i, sorted_j))\n",
    "        pairs_list.append([score, i, label_list[j]])\n",
    "\n",
    "\n",
    "pairs_list = sorted(pairs_list, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "scores_top_k_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 준비한 리뷰 이미지 순서대로 결과 추론\n",
    "출력 예시 : \"메뉴이름\"[\"확률\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유린기 샐러드[0.8497395515441895]\n",
      "유린기 샐러드[0.8475852012634277]\n",
      "유린기 샐러드[0.7529000639915466]\n",
      "유린기 샐러드[0.8216028213500977]\n",
      "유린기 샐러드[0.8347015380859375]\n",
      "유린기 샐러드[0.7983312606811523]\n",
      "유린기 샐러드[0.8235374689102173]\n",
      "유린기 샐러드[0.797694206237793]\n",
      "트레이 짜장[0.7688065767288208]\n",
      "유린기 샐러드[0.8366624116897583]\n",
      "유린기 샐러드[0.8510055541992188]\n",
      "유린기 샐러드[0.8327979445457458]\n",
      "유린기 샐러드[0.828330934047699]\n",
      "유린기 샐러드[0.8112948536872864]\n",
      "유린기 샐러드[0.8266451358795166]\n",
      "유린기 샐러드[0.778620719909668]\n",
      "유린기 샐러드[0.8583508133888245]\n",
      "유린기 샐러드[0.84061199426651]\n",
      "유린기 샐러드[0.8388550281524658]\n",
      "유린기 샐러드[0.8216028213500977]\n",
      "유린기 샐러드[0.8248535990715027]\n",
      "유린기 샐러드[0.7326924204826355]\n",
      "유린기 샐러드[0.8160733580589294]\n",
      "유린기 샐러드[0.7902628779411316]\n",
      "유린기 샐러드[0.7529000639915466]\n",
      "유린기 샐러드[0.8813169002532959]\n",
      "유린기 샐러드[0.8281384110450745]\n",
      "유린기 샐러드[0.8236373662948608]\n",
      "유린기 샐러드[0.788112223148346]\n",
      "유린기 샐러드[0.781449556350708]\n",
      "트레이 짜장[0.8545013070106506]\n",
      "유린기 샐러드[0.797694206237793]\n",
      "유린기 샐러드[0.8236373662948608]\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(scores_top_k_idx, scores_top_k_values):\n",
    "    print(label_list[i[0]]+str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 20.22it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'마라샹궈' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/user/run.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B210.125.85.67/home/user/run.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m     result[_\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mappend(count)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B210.125.85.67/home/user/run.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B210.125.85.67/home/user/run.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m answer \u001b[39m=\u001b[39m label_list\u001b[39m.\u001b[39;49mindex(menu_name)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B210.125.85.67/home/user/run.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m scores_top_k_idx:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B210.125.85.67/home/user/run.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39mif\u001b[39;00m j[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m answer:\n",
      "\u001b[0;31mValueError\u001b[0m: '마라샹궈' is not in list"
     ]
    }
   ],
   "source": [
    "# 추가적으로 변형한 코드라 사용할 필요 없음\n",
    "#####################\n",
    "\n",
    "\n",
    "test_data_dir_path = './datasets/차알/crops/'\n",
    "target_list = os.listdir(test_data_dir_path)\n",
    "result = [[]]\n",
    "score_function = cos_sim\n",
    "\n",
    "for _, menu_name in enumerate(target_list):\n",
    "    \n",
    "    result.append([menu_name])\n",
    "\n",
    "    test_data_path = test_data_dir_path + menu_name\n",
    "\n",
    "    test_original_images = []\n",
    "\n",
    "    for i, filename in enumerate([filename for filename in os.listdir(test_data_path) if filename.endswith(\".png\") or filename.endswith(\".jpg\")]):\n",
    "\n",
    "        name = os.path.splitext(filename)[0]\n",
    "        image = Image.open(os.path.join(test_data_path, filename)).convert(\"RGB\")\n",
    "\n",
    "        test_original_images.append(image)\n",
    "\n",
    "    test_encoded_images = model.encode(test_original_images, batch_size=128, convert_to_tensor=True, show_progress_bar=True)\n",
    "    result[_+1].append(len(test_encoded_images))\n",
    "\n",
    "    query_chunk_size = 5000\n",
    "    corpus_chunk_size = 100000\n",
    "    max_pairs = 500000\n",
    "    top_k = 1\n",
    "\n",
    "    pairs = queue.PriorityQueue()\n",
    "    min_score = -1\n",
    "    num_added = 0\n",
    "\n",
    "    for corpus_start_idx in range(0, len(menu_encoded_images), corpus_chunk_size):\n",
    "        for query_start_idx in range(0, len(test_encoded_images), query_chunk_size):\n",
    "            scores = score_function(test_encoded_images[query_start_idx:query_start_idx+query_chunk_size], menu_encoded_images[corpus_start_idx:corpus_start_idx+corpus_chunk_size])\n",
    "            \n",
    "            scores_top_k_values, scores_top_k_idx = torch.topk(scores, min(top_k, len(scores[0])), dim=1, largest=True, sorted=False)\n",
    "            scores_top_k_values = scores_top_k_values.cpu().tolist()\n",
    "            scores_top_k_idx = scores_top_k_idx.cpu().tolist()\n",
    "    \n",
    "    count = 0\n",
    "    if menu_name == 'etc':\n",
    "        for j in scores_top_k_values:\n",
    "            if j[0] < 0.71:\n",
    "                count += 1\n",
    "        result[_+1].append(count)\n",
    "        continue\n",
    "\n",
    "    answer = label_list.index(menu_name)\n",
    "    for j in scores_top_k_idx:\n",
    "        if j[0] == answer:\n",
    "            count += 1\n",
    "    result[_+1].append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['마라샹궈', 5, 0],\n",
       " ['마파두부', 3, 3],\n",
       " ['차알 볶음밥', 37, 32],\n",
       " ['차우멘', 20, 11],\n",
       " ['차알 순두부', 10, 4],\n",
       " ['깐풍가지새우', 28, 13],\n",
       " ['로제샹궈', 21, 19],\n",
       " ['마라 짬뽕', 52, 29],\n",
       " ['제네럴 쏘 치킨', 4, 4],\n",
       " ['차알 탕수육', 12, 6],\n",
       " ['오렌지 치킨', 4, 3],\n",
       " ['유린기 샐러드', 33, 31],\n",
       " ['차알 순두부 핫팟', 7, 3],\n",
       " ['etc', 16, 6],\n",
       " ['몽골리안 비프', 5, 5],\n",
       " ['트레이 짜장', 39, 31]]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 돌릴 필요 없음\n",
    "#####################\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
